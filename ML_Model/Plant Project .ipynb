{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91bfd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f1d201",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"./Plant_Village_Data_Set/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7e256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b2f1b4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d7f204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# List all subdirectories (each corresponds to a disease category)\n",
    "subdirectories = [subdir for subdir in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, subdir))]\n",
    "\n",
    "# Create lists to store image paths and corresponding labels\n",
    "image_paths = []\n",
    "labels = []\n",
    "sum = 0\n",
    "# Iterate through each subdirectory (disease category)\n",
    "for subdir in subdirectories:\n",
    "    subdir_path = os.path.join(dataset_dir, subdir)\n",
    "    \n",
    "    subdir_images = [os.path.join(subdir_path, img) for img in os.listdir(subdir_path) if img.lower().endswith('.jpg')]\n",
    "\n",
    "    sum += (len(subdir_images))\n",
    "    image_paths.extend(subdir_images)\n",
    "    labels.extend([subdir] * len(subdir_images))\n",
    "print(sum)\n",
    "# Split the data into training and testing sets\n",
    "train_paths, test_paths, train_labels, test_labels = train_test_split(image_paths, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6ed892",
   "metadata": {},
   "outputs": [],
   "source": [
    "subdirectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb23c005",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42b4e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "def load_images(image_paths):\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        image = cv2.imread(path)  # Load image using OpenCV\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        images.append(image)\n",
    "    return np.array(images)\n",
    "\n",
    "# Load training and testing images\n",
    "train_images = load_images(train_paths)\n",
    "test_images = load_images(test_paths)\n",
    "\n",
    "# Convert labels to categorical format (if using one-hot encoding)\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "num_classes = len(np.unique(train_labels_encoded))\n",
    "train_labels_onehot = to_categorical(train_labels_encoded, num_classes=num_classes)\n",
    "test_labels_onehot = to_categorical(test_labels_encoded, num_classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcc67ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Preprocess images (normalize pixel values and resize)\n",
    "def preprocess_images(images, target_size=(224, 224)):\n",
    "    processed_images = []\n",
    "    for img in images:\n",
    "        img = img.astype('float32') / 255.0  # Normalize pixel values\n",
    "        img = cv2.resize(img, target_size)   # Resize image\n",
    "        processed_images.append(img)\n",
    "    return np.array(processed_images)\n",
    "\n",
    "# Preprocess training and testing images\n",
    "train_images_processed = preprocess_images(train_images)\n",
    "test_images_processed = preprocess_images(test_images)\n",
    "\n",
    "# Check shapes of preprocessed data\n",
    "print(\"Train Images Shape:\", train_images_processed.shape)\n",
    "print(\"Test Images Shape:\", test_images_processed.shape)\n",
    "print(\"Train Labels Shape:\", train_labels_onehot.shape)\n",
    "print(\"Test Labels Shape:\", test_labels_onehot.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2e9ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define CNN model architecture\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images_processed, train_labels_onehot,\n",
    "                    batch_size=32, epochs=10, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff557ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(test_images_processed, test_labels_onehot)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcffe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data\n",
    "predictions = model.predict(test_images_processed)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(test_labels_encoded, predicted_labels)\n",
    "\n",
    "# Display the confusion matrix\n",
    "classes = label_encoder.classes_\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "\n",
    "# Plot confusion matrix\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
